{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Important libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport shutil\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom keras.utils import to_categorical\nfrom tensorflow.keras import Sequential\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-22T08:59:33.459378Z","iopub.execute_input":"2023-07-22T08:59:33.459784Z","iopub.status.idle":"2023-07-22T08:59:33.468757Z","shell.execute_reply.started":"2023-07-22T08:59:33.459750Z","shell.execute_reply":"2023-07-22T08:59:33.467223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_data = pd.read_csv(\"/kaggle/input/skin-cancer-dataset/HAM10000_metadata.csv\")\nmeta_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:25:57.862049Z","iopub.execute_input":"2023-07-22T06:25:57.862402Z","iopub.status.idle":"2023-07-22T06:25:57.924980Z","shell.execute_reply.started":"2023-07-22T06:25:57.862374Z","shell.execute_reply":"2023-07-22T06:25:57.923894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Unique Cancer types represented in data.\")\nprint(meta_data.dx.unique(),\"\\n\")\n\n# Handling categorical data\nencoder = LabelEncoder()\nmeta_data[\"dx_label\"] = encoder.fit_transform(meta_data[\"dx\"])\n\n# Display of labels and their integer encoding\nprint(\"Cancer types and their integer encoding\")\nprint(encoder.classes_)\nprint(encoder.transform(encoder.classes_))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:25:58.246877Z","iopub.execute_input":"2023-07-22T06:25:58.247248Z","iopub.status.idle":"2023-07-22T06:25:58.264297Z","shell.execute_reply.started":"2023-07-22T06:25:58.247220Z","shell.execute_reply":"2023-07-22T06:25:58.261880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:25:58.616255Z","iopub.execute_input":"2023-07-22T06:25:58.616607Z","iopub.status.idle":"2023-07-22T06:25:58.633252Z","shell.execute_reply.started":"2023-07-22T06:25:58.616580Z","shell.execute_reply":"2023-07-22T06:25:58.632232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data sorting, visualization & augmentation.","metadata":{}},{"cell_type":"markdown","source":"## Data sorting","metadata":{}},{"cell_type":"code","source":"# Sorting images into appropriate directories in order\n# to fascilitate real-time data augmentation while training.\n\n# Using the cancer type label for directory creation.\ndir_names = encoder.transform(encoder.classes_)\n\n# Data Sorting process.\nimages_dir = r\"/kaggle/input/skin-cancer-dataset/Skin Cancer/Skin Cancer\"\ntrain_images_dir = r\"/kaggle/working/train/\"\n\n\ndef create_dirs(dir_path:str, dir_names:list):\n    \"\"\"\n    This function creates directories within specified directory path\n    with the provided list of directory names.\n    \n    Inputs\n        dir_path:str - The path to which the new directories will reside in.\n        dir_names:list - List name(s) of directories to be created.\n    \"\"\"\n    # Looping through to create directories in new location.\n    for dir_name in dir_names:\n        try:\n            os.makedirs(os.path.join(dir_path, str(dir_name)))\n        except FileExistsError:\n            continue\n\n            \n# Creating new directories. \ncreate_dirs(train_images_dir, dir_names)\n\n# Looping through each image in previous folder and\n# assigning them to the appropriate folder\nfor image in os.scandir(images_dir):\n    try:\n        # attempting to rename image (moving to new dir).\n        img_name = image.name.split(\".\")[0]\n        img_cancer_type = str(meta_data.dx_label[meta_data.image_id == img_name].item()) # Retrieving the dx_label for image.\n        shutil.copy(os.path.join(images_dir, image.name), os.path.join(train_images_dir, img_cancer_type, image.name))\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:26:00.099771Z","iopub.execute_input":"2023-07-22T06:26:00.100432Z","iopub.status.idle":"2023-07-22T06:28:07.808959Z","shell.execute_reply.started":"2023-07-22T06:26:00.100398Z","shell.execute_reply":"2023-07-22T06:28:07.807937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==========================================================================================#\n# DO NOT RE-RUN THIS CELL MULTIPLE TIMES IF VALIDATION DIRECTORY HAS ALREADY BEEN POPULATED #\n# ==========================================================================================#\n\nvalidation_images_dir = r\"/kaggle/working/validation/\"\ninds = [] # list to contain directory names of each image.\nfive_percent_content = {} # Dictionary containing cancer type and the value that is 5% of total number of that type of cancer images.\n\n# Finding out how many images of each cancer type exist\nfor dir_name in os.scandir(train_images_dir): # Iterating over all train images folders.\n    for cancer_img in os.scandir(dir_name): # Iterating over all images in all folders.\n        inds.append(cancer_img.path.split(\"/\")[4]) # Appending each images directro number to inds for counting & sorting purpose.\n        \n\n# Calculating number of specific type images &\n# Calculating what 5% of each image type will be.\nfor directory in dir_names:\n    total_amt = inds.count(str(directory))\n    c_type = encoder.inverse_transform([int(directory)])[0]\n    print(f\"There are {total_amt} images of {c_type} cancer.\")\n    print(f\"5% of {c_type} cancer images is: {round(total_amt * 0.05, 0)}\\n\")\n    five_percent_content[str(directory)] = round(total_amt * 0.05, 0)\n\n\n# Creating and populating validation set directory\ncreate_dirs(validation_images_dir, dir_names)\n\n\n# Moving 5% of each type into its respective validation folder.\n# Looping through each sub directory\nfor sub_dir in os.scandir(train_images_dir):\n    # Getting all images in current subdir\n    images_paths = [image.path for image in os.scandir(sub_dir)]\n    # Extracting 5% of images from each directory.\n    for image_path in images_paths[: int(five_percent_content[str(sub_dir.name)])]:\n        # Getting category for individual images\n        image_category = image_path.split(\"/\")[4]\n        # creating new image path and moving old image to new destination.\n        shutil.move(image_path, os.path.join(validation_images_dir, image_category, image_path.split(\"/\")[-1]))\n# ==========================================================================================#\n# DO NOT RE-RUN THIS CELL MULTIPLE TIMES IF VALIDATION DIRECTORY HAS ALREADY BEEN POPULATED #\n# ==========================================================================================#","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:28:07.811507Z","iopub.execute_input":"2023-07-22T06:28:07.812173Z","iopub.status.idle":"2023-07-22T06:28:07.868459Z","shell.execute_reply.started":"2023-07-22T06:28:07.812133Z","shell.execute_reply":"2023-07-22T06:28:07.867538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data visualization","metadata":{}},{"cell_type":"code","source":"top_n = 20 # Variable for top-n random images to select from.\nimage_sample = [] # List containing array of images.\nimage_sample_category = [] # List containing image type\n\nfor sub_dir in os.scandir(train_images_dir):\n    # Getting all images in current subdir\n    images_paths = [image.path for image in os.scandir(sub_dir)]\n    current_dir_img_paths = [] # List of top n images from current sub-dir.\n    # Extracting random image from each directory.\n    for image_path in images_paths[:top_n]:\n        current_dir_img_paths.append(image_path) # Appending images from current sub-dir to orary list\n        image = random.choice(current_dir_img_paths) # Selecting random image from current images.\n        image = cv2.imread(image)[:,:,::-1] # Reading in image and arranging colors.\n    image_sample_category.append((encoder.inverse_transform([int(image_path.split(\"/\")[4])])[0])) # Appending image category name to array.\n    image_sample.append(image) # Appending image array to list.\n        \n\nplt.figure(figsize = (15,10))\nfor num in range(0, len(image_sample)):\n    plt.subplot(3, 3 ,num + 1)\n    plt.axis(False)\n    plt.title(f\"Image of {image_sample_category[num]}. cancer.\")\n    plt.imshow(image_sample[num]);","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:28:56.407346Z","iopub.execute_input":"2023-07-22T06:28:56.407711Z","iopub.status.idle":"2023-07-22T06:28:59.089377Z","shell.execute_reply.started":"2023-07-22T06:28:56.407681Z","shell.execute_reply":"2023-07-22T06:28:59.088480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation","metadata":{}},{"cell_type":"code","source":"img_size = 250 # Augmented image size.\nbatch_size = 32\n\ngenerator = ImageDataGenerator(zoom_range = 0.3,\n                               rotation_range = 90,\n                               horizontal_flip = True,\n                               vertical_flip = True,\n                               validation_split = 0.1,)\n\n# Augmented training set\naugmented_train_data = generator.flow_from_directory(\n                            train_images_dir,\n                            target_size = (img_size, img_size),\n                            batch_size = batch_size,\n                            subset = \"training\")\n\n# Un-augmented test set\nunaugmented_test_data = generator.flow_from_directory(\n                            train_images_dir,\n                            target_size = (img_size, img_size),\n                            batch_size = 32,\n                            subset = \"validation\")\n\n# Un-augmented dev set.\nunaugmented_dev_data = image_dataset_from_directory(\n                            validation_images_dir,\n                            image_size = (img_size, img_size),\n                            batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:56:37.767061Z","iopub.execute_input":"2023-07-22T07:56:37.767438Z","iopub.status.idle":"2023-07-22T07:56:38.098455Z","shell.execute_reply.started":"2023-07-22T07:56:37.767409Z","shell.execute_reply":"2023-07-22T07:56:38.097540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training, evaluation.","metadata":{}},{"cell_type":"markdown","source":"## Model training.","metadata":{}},{"cell_type":"code","source":"# Defining model architecture\nmodel = Sequential()\n\n# Layer one\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = (3,3), input_shape= (250, 250, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\n# Layer two\nmodel.add(Conv2D(32, kernel_size = (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\n# Layer three\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation(\"relu\"))\n\n# # Dropout\n# model.add(Dropout(0.5))\n\n# Layer four\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Activation(\"relu\"))\n\n# Layer five\nmodel.add(Dense(7))\nmodel.add(Activation(\"softmax\"))\n\n\nmodel.compile(\n    loss = \"categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = [\"accuracy\"],\n)\n\n# model.summary()\n# fitting/training model\nhistory = model.fit_generator(augmented_train_data, validation_data = unaugmented_test_data, epochs = 15, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T06:45:16.221470Z","iopub.execute_input":"2023-07-22T06:45:16.222245Z","iopub.status.idle":"2023-07-22T07:41:45.954932Z","shell.execute_reply.started":"2023-07-22T06:45:16.222206Z","shell.execute_reply":"2023-07-22T07:41:45.953944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Extracting metrics\nmetrics = history.history\n\ntrain_loss = metrics[\"loss\"]\ntrain_accuracy = metrics[\"accuracy\"]\n\ntest_loss = metrics[\"val_loss\"]\ntest_accuracy = metrics[\"val_accuracy\"]\n\n# Visualizing metrics\nplt.figure(figsize = (13,4))\nplt.subplot(1,2,1)\nplt.title(\"Loss.\")\nplt.plot(train_loss, label = \"Train\");\nplt.plot(test_loss, label = \"Test\");\nplt.grid(True)\nplt.legend(loc = \"best\");\n\nplt.subplot(1,2,2)\nplt.title(\"Accuracy.\")\nplt.plot(train_accuracy, label = \"Train\");\nplt.plot(test_accuracy, label = \"Test\");\nplt.grid(True)\nplt.legend(loc = \"best\");","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:42:11.779066Z","iopub.execute_input":"2023-07-22T07:42:11.779429Z","iopub.status.idle":"2023-07-22T07:42:12.390552Z","shell.execute_reply.started":"2023-07-22T07:42:11.779397Z","shell.execute_reply":"2023-07-22T07:42:12.388653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.predict(unaugmented_dev_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T07:57:55.661413Z","iopub.execute_input":"2023-07-22T07:57:55.661773Z","iopub.status.idle":"2023-07-22T07:57:58.633410Z","shell.execute_reply.started":"2023-07-22T07:57:55.661742Z","shell.execute_reply":"2023-07-22T07:57:58.632434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_class = [] # List containing true labels for each image.\npredicted_class = [predicted_label.argmax() for predicted_label in result]\n\nfor file_path in unaugmented_dev_data.file_paths: # Looping through each image file path in dev set\n    true_class.append(int(file_path.split(\"/\")[4])) # Appending the image folder name/cancer type label to list\n\n# Understanding classification power of model on each class    \nreport = classification_report(true_class, predicted_class)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T09:01:42.817522Z","iopub.execute_input":"2023-07-22T09:01:42.817954Z","iopub.status.idle":"2023-07-22T09:01:42.839257Z","shell.execute_reply.started":"2023-07-22T09:01:42.817917Z","shell.execute_reply":"2023-07-22T09:01:42.837970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Investigating F1 score.    \n# Calculating confusion matrix\nplt.title(\"Heatmap of devset prediction and actual label\", fontsize = 13)\ncm = confusion_matrix(true_class, predicted_class)\nsns.heatmap(cm, cmap = \"Reds\", annot = True, fmt = \"d\");\nplt.ylabel(\"True Class\");\nplt.xlabel(\"Predicted Class\");","metadata":{"execution":{"iopub.status.busy":"2023-07-22T09:03:57.650420Z","iopub.execute_input":"2023-07-22T09:03:57.650836Z","iopub.status.idle":"2023-07-22T09:03:58.185845Z","shell.execute_reply.started":"2023-07-22T09:03:57.650803Z","shell.execute_reply":"2023-07-22T09:03:58.184826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}